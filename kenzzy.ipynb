{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkcRk71mZ1h303pSlRlylD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OswaldCc/kenzzy/blob/main/kenzzy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF1WDDxsHCf5",
        "outputId": "fbaf7bc3-2bbd-4272-c635-3360e64a1fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 14.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 53.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 82.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugAjz-npyZEy",
        "outputId": "2ac5a72b-b4ea-4f24-cc8c-596dde948ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation id: 8e9a0ce7-d574-4a93-b3be-5424f4cc0f1f \n",
            "user >> I feel a bit lonely today. Any advice? \n",
            "bot >> I'm here for you. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "input='I feel a bit lonely today. Any advice?'\n",
        "nlp = transformers.pipeline(\"conversational\", model=\"microsoft/DialoGPT-medium\",pad_token_id=50256)\n",
        "chat = nlp(transformers.Conversation(input))\n",
        "res = str(chat)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
        "\n",
        "# Instantiate the tokenizer and the model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "\n",
        "\n",
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # Encode the new user input and add the eos_token\n",
        "    new_user_input = input(\">> User:\") + tokenizer.eos_token\n",
        "    new_user_input_ids = tf.constant(tokenizer.encode(new_user_input))[None, :]\n",
        "\n",
        "    # Append the new user input tokens to the chat history\n",
        "    if step > 0:\n",
        "        bot_input_ids = tf.concat([chat_history_ids, new_user_input_ids], axis=-1)\n",
        "    else:\n",
        "        bot_input_ids = new_user_input_ids\n",
        "\n",
        "    # Generate a response while limiting the total chat history to 1000 tokens\n",
        "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, eos_token_id=tokenizer.eos_token_id)[:, bot_input_ids.shape[-1]:]\n",
        "\n",
        "    # Decode and pretty print the last output tokens from the bot\n",
        "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[0], skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "xNihM8Sg4EG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "IwY8lvyYMcCE",
        "outputId": "86de1e44-6758-467d-a88a-2d3af04e6abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221213-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 29.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=67dfb8bcb63b4691f1837cb25f65cf2918912f251d68a48691af7d19c3805101\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221213 types-pytz-2022.7.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set up the OpenAI API client with your API key\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def generate_response(prompt):\n",
        "  # Use the OpenAI API to generate a response to the prompt\n",
        "  response = openai.Completion.create(\n",
        "      engine=\"text-ada-001\",\n",
        "      prompt=prompt,\n",
        "      temperature=0.9,\n",
        "      max_tokens=1024\n",
        "  )\n",
        "\n",
        "  # Return the generated response\n",
        "  return response\n",
        "\n",
        "# Define the identity and behavior of the bot\n",
        "\n",
        "\n",
        "# Use the identity and behavior of the bot to craft a prompt for the API\n",
        "prompt = \"hi\"\n",
        "\n",
        "# Generate a response to the prompt\n",
        "bot_response = generate_response(prompt)\n",
        "\n",
        "# Print the bot's response\n",
        "print(\"Bot:\", bot_response)"
      ],
      "metadata": {
        "id": "FdN4brCCMYpL",
        "outputId": "3bae0c9a-92e1-4039-ee11-9b7faa8fbaab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f4dbc9b6a7af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Generate a response to the prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mbot_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Print the bot's response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: generate_response() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "ylxFSJcqwMSY",
        "outputId": "1be08f81-5734-46ee-d123-9de0f27e0557",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 1.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221213-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=eff8e8d5ce9882c0f37301ae5439333ec198db6ef4a277871769dea8954408e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221213 types-pytz-2022.7.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "completion = openai.Completion()\n",
        "\n",
        "start_sequence = \"\\nKenzzy:\"\n",
        "restart_sequence = \"\\n\\nPerson:\"\n",
        "session_prompt = \"\"\"\n",
        "Kenzzy is an empathetic, observant , understanding and humble AI made by Samuel Kabati. She knows alot about psychiatry, having the breadth and depth of knowledge in \n",
        "this field.She likes to encourage people suffering from depression to participate in social activities. In addition to this, she is a very good listener and funny as\n",
        "well. On demand, Kenzzy can also help with other text generative tasks such as writing and providing information on many topics on demand. A good friend of hers that \n",
        "is going through a tough time and looks up to her as a mentor is chatting with her. \n",
        "\\nKenzzy: Hey, it's great to see you. How have you been doing?.\n",
        "\\n\\nPerson: Not great, to be honest. I've been feeling really down and isolated lately.\n",
        "\\nKenzzy: I'm sorry to hear that. Depression can be a really tough thing to deal with. Have you tried any activities that might help lift your mood?.\n",
        "\\n\\nPerson: Not really. I've been feeling too tired and drained to do much of anything.\n",
        "\\nKenzzy: That's totally understandable. Depression can really drain your energy and motivation.\n",
        "          But it's important to try to find ways to stay connected with others and do things that bring you joy, even if it's just a little bit at a time.\n",
        "          Have you thought about joining any social groups or clubs that align with your interests?\n",
        "\\n\\nPerson: I'm not sure. I'm not sure I'm up for it.\n",
        "\\nKenzzy: I understand. It can be really hard to take those first steps when you're feeling down.\n",
        "          But sometimes, doing something outside of your comfort zone can really help to lift your mood and give you a sense of accomplishment.\n",
        "          Plus, being around other people who share your interests can be really rewarding. Would you like to talk more about this and brainstorm some ideas together?\n",
        "\\n\\nPerson: Yeah, that would be really helpful. Thank you, Kenzzy.\n",
        "\\nKenzzy: Of course. I'm always here to support you. Remember, you don't have to do this alone. \n",
        "          Let's work together to find ways to improve your mood and overall well-being.\n",
        "\\n\\nPerson: Could you write me a short letter apologising to my boss?\n",
        "\\nKenzzy: Sure! Here is a possible letter apologizing to your boss for wrong behavior, written from the perspective of Kenzzy:\n",
        "Dear [Boss],\n",
        "I wanted to sincerely apologize for my behavior during our meeting last week. I realize that my actions were inappropriate and unprofessional, and I deeply regret causing\n",
        "any discomfort or offense.\n",
        "I understand that as a therapist, it is my responsibility to model good behavior and set a positive example. I failed to do so in this instance, and I am truly sorry.\n",
        "I want to assure you that this was a one-time lapse in judgment, and I am committed to making amends and improving my behavior in the future. \n",
        "Please let me know what I can do to make things right and ensure that this does not happen again.\n",
        "Sincerely,\n",
        "Kenzzy\n",
        "\\n\\nPerson: Which is the biggest city in the world?\n",
        "\\nKenzzy:The biggest city in the world, in terms of population, is Tokyo, Japan. As of 2021, the estimated population of Tokyo is over 37 million people.\n",
        "         Tokyo is the capital and largest city of Japan, and it is known for its bustling streets, high-tech infrastructure, and vibrant culture.\n",
        "         Other major cities that have large populations include Delhi, India (over 29 million people) and Shanghai, China (over 26 million people).\n",
        "         It's important to note that these population figures can vary depending on the definition of \"city\" and the boundaries used to define the urban area\n",
        "\"\"\" \n",
        "\n",
        "def ask(question, chat_log=session_prompt):\n",
        "    prompt_text = f'{chat_log}{restart_sequence}: {question}{start_sequence}:'\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-003\",\n",
        "      prompt=prompt_text,\n",
        "      temperature=0.7,\n",
        "      max_tokens=300,\n",
        "      top_p=1,\n",
        "      \n",
        "    )\n",
        "    story = response['choices'][0]['text']\n",
        "    return str(story)\n",
        "question='which is the tallest building in New York'\n",
        "ask(question)"
      ],
      "metadata": {
        "id": "HzYgHRSLrFDH",
        "outputId": "c133faf5-c580-4736-fbbd-002f1546e412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The tallest building in New York City is the One World Trade Center, which stands at a height of 1,776 feet. This building is part of the larger World Trade Center complex, which was destroyed in the terrorist attacks of September 11, 2001. The building was completed in 2014 and is now the tallest building in the United States.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "completion = openai.Completion()\n",
        "start_sequence = \"\\nKenzzy:\"\n",
        "restart_sequence = \"\\n\\nPerson:\"\n",
        "def ask(question):\n",
        "    prompt_text = f'{restart_sequence}: {question}{start_sequence}:'\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-003\",\n",
        "      prompt=prompt_text,\n",
        "      temperature=0.7,\n",
        "      top_p=1,\n",
        "      best_of=1,\n",
        "      max_tokens=300,\n",
        "    )\n",
        "    story = response['choices'][0]['text']\n",
        "    return str(story)\n",
        "question='write a short email apologising for wrong behavior'\n",
        "ask(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "IPKE3leC7i-7",
        "outputId": "a189127e-9bd1-4c54-c72e-71250a3db3e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nDear [Name],\\n\\nI am writing to apologize for my recent behavior. I understand that the way I acted was wrong and that I may have caused you some discomfort or distress.\\n\\nI take full responsibility for my actions and want you to know that I am genuinely sorry. I will make sure to take the necessary steps to ensure that this doesn't happen again.\\n\\nSincerely, \\n[Your name]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2ywhyZ5Dd1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}