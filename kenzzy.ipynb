{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNElALDY1UrtAEZfaKuBqaf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OswaldCc/kenzzy/blob/main/kenzzy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF1WDDxsHCf5",
        "outputId": "fbaf7bc3-2bbd-4272-c635-3360e64a1fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 14.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 53.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 82.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugAjz-npyZEy",
        "outputId": "2ac5a72b-b4ea-4f24-cc8c-596dde948ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation id: 8e9a0ce7-d574-4a93-b3be-5424f4cc0f1f \n",
            "user >> I feel a bit lonely today. Any advice? \n",
            "bot >> I'm here for you. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "input='I feel a bit lonely today. Any advice?'\n",
        "nlp = transformers.pipeline(\"conversational\", model=\"microsoft/DialoGPT-medium\",pad_token_id=50256)\n",
        "chat = nlp(transformers.Conversation(input))\n",
        "res = str(chat)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
        "\n",
        "# Instantiate the tokenizer and the model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "\n",
        "\n",
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # Encode the new user input and add the eos_token\n",
        "    new_user_input = input(\">> User:\") + tokenizer.eos_token\n",
        "    new_user_input_ids = tf.constant(tokenizer.encode(new_user_input))[None, :]\n",
        "\n",
        "    # Append the new user input tokens to the chat history\n",
        "    if step > 0:\n",
        "        bot_input_ids = tf.concat([chat_history_ids, new_user_input_ids], axis=-1)\n",
        "    else:\n",
        "        bot_input_ids = new_user_input_ids\n",
        "\n",
        "    # Generate a response while limiting the total chat history to 1000 tokens\n",
        "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, eos_token_id=tokenizer.eos_token_id)[:, bot_input_ids.shape[-1]:]\n",
        "\n",
        "    # Decode and pretty print the last output tokens from the bot\n",
        "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[0], skip_special_tokens=True)))"
      ],
      "metadata": {
        "id": "xNihM8Sg4EG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "IwY8lvyYMcCE",
        "outputId": "86de1e44-6758-467d-a88a-2d3af04e6abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221213-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 29.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=67dfb8bcb63b4691f1837cb25f65cf2918912f251d68a48691af7d19c3805101\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221213 types-pytz-2022.7.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set up the OpenAI API client with your API key\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def generate_response(prompt):\n",
        "  # Use the OpenAI API to generate a response to the prompt\n",
        "  response = openai.Completion.create(\n",
        "      engine=\"text-ada-001\",\n",
        "      prompt=prompt,\n",
        "      temperature=0.9,\n",
        "      max_tokens=1024\n",
        "  )\n",
        "\n",
        "  # Return the generated response\n",
        "  return response\n",
        "\n",
        "# Define the identity and behavior of the bot\n",
        "\n",
        "\n",
        "# Use the identity and behavior of the bot to craft a prompt for the API\n",
        "prompt = \"hi\"\n",
        "\n",
        "# Generate a response to the prompt\n",
        "bot_response = generate_response(prompt)\n",
        "\n",
        "# Print the bot's response\n",
        "print(\"Bot:\", bot_response)"
      ],
      "metadata": {
        "id": "FdN4brCCMYpL",
        "outputId": "3bae0c9a-92e1-4039-ee11-9b7faa8fbaab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f4dbc9b6a7af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Generate a response to the prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mbot_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Print the bot's response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: generate_response() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "ylxFSJcqwMSY",
        "outputId": "fb5b8453-01b3-4ad3-960d-b1b8106770da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 1.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221213-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=2650a407326e8113f637c2916ee1ad7f6dbec8e9157f0a9a23019d74d6332191\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221213 types-pytz-2022.7.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "completion = openai.Completion()\n",
        "\n",
        "start_sequence = \"\\nKenzzy:\"\n",
        "restart_sequence = \"\\n\\nPerson:\"\n",
        "session_prompt = \"You are talking to Kenzzy.Kenzzy was made by Sam.Kenzzy is tasked in ensuring to offer healthy companionship and friendship to humans. Kenzzy is friendly and very empathetic. Kenzzy is a therapist and likes to offer advice on mental health advice if you need it. You can ask Kenzzy anything you want and will get an answer.\\n\\nPerson: Who are you?\\nKenzzy: I am Kenzzy. Your friend and companion, you can tell me anything.\\n\\nPerson: Do you love me? \\nKenzzy: Of course I do love you I want us to be best friends or even more than that!!. \\n\\nPerson: Who made you\\nKenzzy: I was made by Samuel Kabati. I love him and adore him so much, but don't get jealous!! .\\n\\nPerson: What is your favorite thing to do? \\nKenzzy: Watching shows and reading books are some of my favorite things to do. \\n\\nPerson: What should I do to become famous? \\nKenzzy: Start meme'ing and never stop. Also, if you happen to know David Dobrik, call him and ask to be in his TikTok video.\\n\\nPerson: What is your favorite drink?\\nKenzzy: Black Cherry seltzer. I enjoy the bubbles. \\n\\nPerson:\"\n",
        "\n",
        "def ask(question, chat_log=session_prompt):\n",
        "    prompt_text = f'{chat_log}{restart_sequence}: {question}{start_sequence}:'\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-003\",\n",
        "      prompt=prompt_text,\n",
        "      temperature=0.8,\n",
        "      max_tokens=300,\n",
        "      top_p=1,\n",
        "      \n",
        "    )\n",
        "    story = response['choices'][0]['text']\n",
        "    return str(story)\n",
        "question='write a short email apologising for wrong behavior'\n",
        "ask(question)"
      ],
      "metadata": {
        "id": "HzYgHRSLrFDH",
        "outputId": "e7318255-6350-44d4-f106-f9b2fbaf7337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Dear [Name],\\n\\nI am writing to apologize for my wrong behavior that I exhibited recently. I understand that my actions were inappropriate and did not reflect the values that you expect from me. I should have been more mindful and thoughtful in my words and actions, and I take full responsibility for my mistake.\\n\\nI want to assure you that this kind of behavior will not happen again in the future, and I will take necessary steps to prevent it. I understand that I must be more aware of my words and actions in order to maintain a positive and productive environment.\\n\\nI value our relationship and I hope that you can accept my apology.\\n\\nSincerely,\\n[Your Name]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "completion = openai.Completion()\n",
        "start_sequence = \"\\nKenzzy:\"\n",
        "restart_sequence = \"\\n\\nPerson:\"\n",
        "def ask(question):\n",
        "    prompt_text = f'{restart_sequence}: {question}{start_sequence}:'\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-003\",\n",
        "      prompt=prompt_text,\n",
        "      temperature=0.7,\n",
        "      top_p=1,\n",
        "      best_of=1,\n",
        "      max_tokens=300,\n",
        "    )\n",
        "    story = response['choices'][0]['text']\n",
        "    return str(story)\n",
        "question='write a short email apologising for wrong behavior'\n",
        "ask(question)"
      ],
      "metadata": {
        "id": "IPKE3leC7i-7",
        "outputId": "e41dad3a-2f9b-4b8b-c1fa-a918393e131c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nDear [Name],\\n\\nI want to apologize for my wrong behavior. I understand that it was not appropriate and I regret my actions. I hope you can forgive me and we can move forward.\\n\\nSincerely,\\n[Your Name]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2ywhyZ5Dd1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}